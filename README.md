
# â­ **README.md â€” Diabetes Prediction using Hybrid Ensemble (ML + ANN + CNN)**

# ğŸ“Œ Diabetes Prediction â€“ Hybrid Machine Learning + Deep Learning Ensemble

A complete end-to-end **medical risk prediction system** using:

* Classical ML Models
* Artificial Neural Network (ANN)
* Convolutional Neural Network (CNN)
* Keras Tuner for hyperparameter optimization
* Hybrid Stacking Ensemble

This project predicts whether a person is diabetic based on medical features (PIMA Indians Diabetes Dataset).
The pipeline includes **EDA â†’ Preprocessing â†’ Feature Engineering â†’ ML/DL Models â†’ Fine-Tuning â†’ Hybrid Ensemble â†’ Evaluation**.

---

# ğŸš€ **Project Features**

### 1. Full end-to-end ML/DL pipeline

### 2. Advanced preprocessing & feature engineering

### 3. ANN + 1D-CNN models with BatchNorm, Dropout

### 4. Hyperparameter tuning using Keras Tuner

### 5. Hybrid Stacking Ensemble (best ML models)

### 6. SMOTE balancing for medical datasets

### 7. Confusion Matrix + ROC Curve visualizations

### 8. Modular, scalable, production-ready architecture

---

# ğŸ§  **Project Architecture**

```
data/
    Diabetes.csv

src/
    data_preprocessing.py
    model_training.py
    fine_tuning.py
    hybrid_ensemble.py
    evaluation.py

results/
    confusion_matrix.png
    ann_tuning/
    cnn_tuning/

main.py
README.md
```

---

# ğŸ“Š **1. Exploratory Data Analysis (EDA)**

Performed a full EDA including:

* âœ” Missing values inspection
* âœ” Handling invalid zeros (Glucose, Insulin, BP, BMIâ€¦)
* âœ” Distribution plots
* âœ” Boxplots for outliers
* âœ” Correlation heatmap
* âœ” Outcome class imbalance check
* âœ” Feature relationships
* âœ” Summary statistics

**Key EDA Insights:**

* Glucose shows the strongest correlation with diabetes.
* Insulin and SkinThickness contain many missing/zero values.
* Age & BMI increase diabetes probability.
* Dataset is imbalanced â†’ requires SMOTE.

---

# ğŸ§¹ **2. Data Preprocessing**

### âœ” Replace zero values with NaN

### âœ” Median imputation

### âœ” Feature scaling (StandardScaler)

### âœ” SMOTE oversampling

### âœ” Feature engineering:

```
Glucose_BMI = Glucose * BMI
Age_BP = Age * BloodPressure
Insulin_sqrt = sqrt(Insulin)
```

These engineered features significantly improved ML & ANN performance.

---

# ğŸ¤– **3. Machine Learning Models**

Trained 5 ML models:

* Random Forest
* Support Vector Machine (SVM)
* Logistic Regression
* K-Nearest Neighbors (KNN)
* XGBoost

All models were trained using:

* Scaled data
* Balanced data
* Cross-validation
* GridSearch-like tuning

---

# ğŸ§¬ **4. Deep Learning Models**

### ğŸŸ¦ **4.1 ANN Model**

Architecture:

* Dense(128, relu) + BatchNorm + Dropout
* Dense(64, relu) + BatchNorm + Dropout
* Dense(16, relu)
* Dense(1, sigmoid)

### ğŸŸ¨ **4.2 CNN Model (1D CNN)**

* Conv1D(128) + BatchNorm + Dropout
* Conv1D(64)
* Flatten
* Dense(32)
* Output: Dense(1, sigmoid)

### ğŸŸ£ **4.3 Model Regularization**

* **Batch Normalization**
* **Dropout (0.3â€“0.5)**
* **EarlyStopping(patience=10)**

---

# ğŸ”§ **5. Hyperparameter Tuning â€“ Keras Tuner**

Both ANN and CNN models were tuned using:

* Random search
* Learning rates
* Number of neurons
* Dropout rates
* Filters (for CNN)

Tuner optimizes: **val_accuracy**

Results are saved automatically in:

```
results/ann_tuning/
results/cnn_tuning/
```

---

# ğŸ§© **6. Hybrid Ensemble Model**

A **StackingClassifier** is built using the best ML models:

* Random Forest
* SVM
* Logistic Regression
* KNN
* XGBoost

Meta-learner: **Logistic Regression**

Deep learning models are *not* used in stacking (industry practice) because:

* Runtimes increase
* Stacking fails with Keras models
* DL models are used separately for comparison

---

# ğŸ“ˆ **7. Final Results**

| Model               | Accuracy |
| ------------------- | -------- |
| RandomForest        | 0.80     |
| SVM                 | 0.79     |
| Logistic Regression | 0.75     |
| KNN                 | 0.80     |
| XGBoost             | 0.78     |
| ANN                 | 0.80     |
| CNN                 | 0.76     |
| ANN_Tuned           | 0.76     |
| CNN_Tuned           | 0.78     |
| **Hybrid Ensemble** | **0.80** |

### âœ” Hybrid Ensemble performs as well as the best models

### âœ” ANN & CNN add nonlinear pattern learning

### âœ” Ensemble improves stability and robustness

---

# ğŸ§® **8. Evaluation Visuals**

### âœ” Confusion Matrix

### âœ” ROC Curve

### âœ” Classification Report

### âœ” Precision, Recall, F1-score

### âœ” AUC score

Confusion Matrix saved to:

```
results/confusion_matrix.png
```

---

# ğŸ›  **9. How to Run the Project**

### ğŸ”¹ Step 1: Install dependencies

```
pip install -r requirements.txt
```

### ğŸ”¹ Step 2: Activate environment

```
conda activate diabetes_env
```

### ğŸ”¹ Step 3: Run the project

```
python main.py
```

---

# ğŸ“¦ **10. Technologies Used**

| Category         | Tech                        |
| ---------------- | --------------------------- |
| ML               | sklearn, XGBoost            |
| DL               | TensorFlow, Keras, SciKeras |
| Tuning           | Keras Tuner                 |
| Oversampling     | SMOTE (imblearn)            |
| Visualization    | Matplotlib                  |
| Deployment-ready | Modular code architecture   |

---

# ğŸ“š **11. Future Improvements**

* Feature selection (mutual information / RFE)
* Optuna tuning for ML models
* SHAP explainability
* Streamlit or Flask deployment
* Model interpretability dashboard
* More feature engineering
* Cross-validation for DL models

---

# ğŸ“œ **12. License**

This project is open-source and free to use for learning, research, and academic purposes.

---

# ğŸ‘¨â€ğŸ’» **13. Developed By**

**Mohd Zakir**
Data Science & Machine Learning Engineering

---

